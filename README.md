# üéôÔ∏è Transcripci√≥n de Audio a Texto con IA# Prototipo: Transcripci√≥n en tiempo real y por archivo/video



Aplicaci√≥n web para transcribir audio y video a texto usando **Hugging Face** (gratis) o **Web Speech API** (navegador). Incluye detecci√≥n autom√°tica de hablantes, descarga en m√∫ltiples formatos (TXT, PDF, SRT, VTT) y dise√±o moderno.Este proyecto es un prototipo minimalista que permite:



![License](https://img.shields.io/badge/license-MIT-blue.svg)- Enviar audio en tiempo real (chunks) desde el navegador al servidor v√≠a WebSocket.

![Node](https://img.shields.io/badge/node-%3E%3D18.0.0-brightgreen.svg)- Subir archivos de audio o video, extraer audio con ffmpeg y transcribir con la API de OpenAI/Whisper.

![Docker](https://img.shields.io/badge/docker-ready-blue.svg)- Descargar la transcripci√≥n en TXT, SRT y VTT (SRT/VTT generados de forma aproximada).



## ‚ú® Caracter√≠sticasRequisitos

- Node.js 18+ (recomendado)

- üé§ **Grabaci√≥n en tiempo real** con detecci√≥n de hablantes (Persona-01, Persona-02...)- Variable de entorno OPENAI_API_KEY con tu clave de OpenAI

- üìÅ **Sube archivos** de audio/video (MP3, WAV, MP4, etc.)

- ü§ñ **IA gratuita** con Hugging Face Whisper (sin tarjeta de cr√©dito)Instalaci√≥n (PowerShell en Windows):

- üåê **Web Speech API** para Chrome/Edge (100% gratis, sin configuraci√≥n)

- üìÑ **Descarga en m√∫ltiples formatos**: TXT, PDF, SRT, VTT```powershell

- üé® **Dise√±o moderno** con gradientes y animacionescd "c:\Users\Leona\OneDrive\Desktop\Nueva carpeta"

- üê≥ **Docker** para despliegue f√°cilnpm install

- üöÄ **Listo para Digital Ocean**$env:OPENAI_API_KEY = "tu_api_key_aqui"  # o define en .env

npm start

## üöÄ Inicio R√°pido```



### Opci√≥n 1: Docker (Recomendado)Ejecutar con Docker (sin instalar Node/npm localmente)



```bashOpci√≥n A ‚Äî docker-compose (recomendado):

# 1. Clonar repositorio

git clone https://github.com/TU_USUARIO/transcripcion-audio.git```powershell

cd transcripcion-audio# Definir la variable de entorno temporalmente en la sesi√≥n

$env:OPENAI_API_KEY = "sk-...tu_api_key..."

# 2. Configurar token de Hugging Face (opcional)

echo "HUGGINGFACE_API_KEY=tu_token_aqui" > .env# Levantar con docker-compose

docker-compose up --build -d

# 3. Ejecutar con Docker

docker-compose up -d# Ver logs

docker-compose logs -f

# 4. Abrir navegador

http://localhost:3000# Parar

```docker-compose down

```

### Opci√≥n 2: Node.js Local

Opci√≥n B ‚Äî docker build + docker run:

```bash

# 1. Clonar repositorio```powershell

git clone https://github.com/TU_USUARIO/transcripcion-audio.gitdocker build -t realtime-transcription .

cd transcripcion-audiodocker run -p 3000:3000 -e OPENAI_API_KEY="sk-...tu_api_key..." --rm realtime-transcription

```

# 2. Instalar dependencias

npm installNotas sobre Docker

- La imagen instala `ffmpeg` en runtime para evitar problemas de compatibilidad.

# 3. Configurar variables (opcional)- El volumen `./tmp` se monta para persistir archivos de transcripci√≥n temporales (puedes borrarlo manualmente).

cp .env.example .env- Aseg√∫rate de exportar `OPENAI_API_KEY` antes de arrancar (o define un archivo `.env` y usa `docker compose --env-file` si prefieres).

# Editar .env con tu token

Uso

# 4. Ejecutar- Abre http://localhost:3000

node server.js- Usa "Iniciar grabaci√≥n" para comenzar a enviar audio en tiempo real. El sistema manda chunks (cada 2s) al servidor y el servidor intenta transcribir cada chunk y devuelve texto parcial.

- Usa el selector de archivos para subir audio o video. Despu√©s de procesar recibir√°s la transcripci√≥n y botones para descargar TXT / SRT / VTT.

# 5. Abrir navegador

http://localhost:3000Notas y limitaciones

```- Este es un prototipo: la transcripci√≥n "en tiempo real" se realiza enviando chunks y transcribiendo cada chunk por separado. Esto produce latencia dependiente de la llamada a la API y podr√≠a generar cortes en la continuidad.

- La generaci√≥n de SRT/VTT es aproximada (no usa timestamps de palabras) y sirve como punto de partida.

## üîë Obtener Token de Hugging Face (GRATIS)- Necesitar√°s una cuenta y clave de OpenAI y el modelo de audio (por ejemplo `whisper-1`) disponible en tu cuenta.



**Tiempo: 2 minutos | Costo: $0 | No requiere tarjeta**Mejoras sugeridas

- Implementar concatenaci√≥n de chunks en el servidor y/o enviar streams para una transcripci√≥n m√°s coherente.

1. Crea cuenta en: https://huggingface.co/join- Usar una librer√≠a que devuelva timestamps por palabra/frase y generar SRT precisos.

2. Ve a: https://huggingface.co/settings/tokens- Manejo avanzado de sesiones, autenticaci√≥n y almacenamiento permanente de transcripciones.

3. Clic en "New token"
4. Nombre: `transcripcion` | Tipo: `Read`
5. Copiar token (empieza con `hf_`)
6. Agregar a `.env`:
   ```
   HUGGINGFACE_API_KEY=hf_tu_token_aqui
   ```

üìñ **Gu√≠a detallada**: Ver `HUGGING-FACE-GRATIS.md`

## üéØ Uso

### 1Ô∏è‚É£ Grabaci√≥n en Tiempo Real (Chrome/Edge)

1. Clic en **"Iniciar Grabaci√≥n"**
2. Permitir acceso al micr√≥fono
3. Hablar normalmente
4. **Pausas de 3+ segundos** cambiar√°n el hablante autom√°ticamente:
   - Primera persona ‚Üí `[Persona-01]`
   - Segunda persona ‚Üí `[Persona-02]`
   - Tercera persona ‚Üí `[Persona-03]`
5. Clic en **"Detener"** cuando termines
6. Seleccionar formato (TXT/PDF) y descargar

### 2Ô∏è‚É£ Subir Archivo (Requiere Token)

1. Clic en **"Elegir archivo"**
2. Seleccionar audio/video (MP3, WAV, MP4, etc.)
3. Clic en **"Subir y transcribir"**
4. Esperar procesamiento (ver barra de progreso)
5. Descargar en formato deseado

### üì• Formatos de Descarga

- **TXT**: Texto plano con etiquetas de hablantes
- **PDF**: Documento formateado con fecha y t√≠tulo
- **SRT**: Subt√≠tulos con timestamps (archivos subidos)
- **VTT**: Subt√≠tulos web (archivos subidos)

## üß† Detecci√≥n de Hablantes

La app detecta autom√°ticamente cambios de hablante usando:

- **Pausas largas** (3+ segundos de silencio)
- **Etiquetado secuencial**: Persona-01, Persona-02, etc.

Ejemplo de transcripci√≥n:
```
[Persona-01] Buenos d√≠as, vamos a comenzar la reuni√≥n.
[Persona-02] Perfecto, tengo la agenda lista.
[Persona-01] Excelente, empecemos con el primer punto.
```

## üåê Desplegar en Digital Ocean

### App Platform ($5/mes - M√°s f√°cil)

```bash
# 1. Subir a GitHub
git init
git add .
git commit -m "Initial commit"
git remote add origin https://github.com/TU_USUARIO/transcripcion-audio.git
git push -u origin main

# 2. En Digital Ocean:
# - Ir a App Platform
# - Conectar repositorio de GitHub
# - Agregar variable: HUGGINGFACE_API_KEY
# - Deploy autom√°tico ‚úÖ
```

üìñ **Gu√≠a completa**: Ver `DEPLOY.md`

## üîß Variables de Entorno

| Variable | Descripci√≥n | Requerido | Ejemplo |
|----------|-------------|-----------|---------|
| `HUGGINGFACE_API_KEY` | Token de Hugging Face | S√≠ (para archivos) | `hf_abc123...` |
| `PORT` | Puerto del servidor | No | `3000` |

## üêõ Soluci√≥n de Problemas

### ‚ùå "Brave no soporta Web Speech API"
- **Soluci√≥n**: Usa Chrome, Edge o sube archivos

### ‚ùå "No se detect√≥ ning√∫n token"
- **Soluci√≥n**: Agregar `HUGGINGFACE_API_KEY` a `.env`

### ‚ùå "Error al descargar PDF"
- **Soluci√≥n**: Verificar que hay texto en el √°rea de transcripci√≥n

### ‚ùå Puerto 3000 ocupado
- **Soluci√≥n**: Cambiar `PORT=8080` en `.env`

## üìÑ Licencia

MIT License

## üë®‚Äçüíª Autor

Desarrollado con ‚ù§Ô∏è

---

**¬øPreguntas?** Abre un [Issue](https://github.com/TU_USUARIO/transcripcion-audio/issues)

## üü¢ Realtime ASR (opcional, local) ‚Äî Vosk

Si quieres usar transcripci√≥n en tiempo real sin servicios externos, puedes instalar Vosk y un modelo local. El servidor intentar√° usar Vosk si est√° disponible y el cliente puede iniciar una conexi√≥n realtime.

Instalaci√≥n (Node):

```pwsh
# Instala binding de Vosk
npm install vosk

# Crea carpeta para modelos
mkdir models
cd models
# Descarga un modelo peque√±o (ejemplo):
# https://alphacephei.com/vosk/models
# Descomprimir en ./models/vosk-model
```

Notas:
- Coloca el modelo en `./models/vosk-model` (ruta esperada por el servidor).
- En Windows es recomendable usar WSL si tienes problemas compilando dependencias.
- Si Vosk no est√° instalado o no encuentra el modelo, la funcionalidad realtime quedar√° deshabilitada y el servidor enviar√° un mensaje de error al cliente.

Uso en la app:
- Abre la p√°gina y pulsa **"üî¥ Realtime ASR"** para enviar audio en tiempo real al servidor.
- El servidor devolver√° mensajes `realtime-partial` y `realtime-final` v√≠a WebSocket.

Si quieres que te ayude a descargar un modelo y probar localmente, dime y lo a√±adimos al Dockerfile o a las instrucciones de setup.
